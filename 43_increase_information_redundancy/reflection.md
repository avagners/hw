# Как правильно думать над моделью данных

## 1. Delivery-сервис (распределение заказов между курьерами)

Проблема:  
Cейчас заказы назначаются курьерам через сложную систему скоринга, но чтобы найти "какой курьер где и когда был", нужно идти через `Order → Assignment → Courier`.

Избыточность:  
Cоздать вторичную структуру `CourierSchedule: Dict[(courier_id, datetime), order_id]`, в дополнение к основному `Order.assignment`.

Плюсы:
- `API` `get_courier_schedule(courier_id, day)` становится простой функцией `O(1)`.
- Логика отображения расписаний, смен и занятости курьеров становится прозрачной.

Минусы:
- При изменении назначения заказа нужно обновлять обе структуры, контролируя консистентность.

## 2. Kafka Consumer: обработка событий basket.confirmed

Проблема:  
При создании заказов из Kafka-сообщений, поиск связанных сущностей происходит через ID, хранящиеся только в одном месте. Часто приходится выполнять много join'ов.

Избыточность:  
Можно в таблице заказов дублировать основные сведения о пользователе и корзине: `user_name`, `basket_total`, `item_count`.

Плюсы:
- Упрощение `API`: данные видны сразу, без join'ов.
- Возможность быстрого аудита, отладки, аналитики.

Минусы:
- Нужно синхронизировать эти дубли при изменениях (например, если пользователь сменит имя — не критично, но всё же).

## 3. Логика в use case "Назначить заказ"

Проблема: сейчас `Order` знает только `courier_id`, но не объясняет, почему он был выбран.

Избыточность: в `Order` добавить поле `scoring_trace`, где сохраняется логика принятия решения (например, `{"reason": "highest_score", "score": 87.5, "alternatives": [...]}`).

Плюсы:
- Лёгкий способ объяснить выбор курьера другим разработчикам, аналитикам.
- Упрощение отладки и возможности объяснимости.

Минусы:
- Дополнительная нагрузка на код скоринга: нужно уметь сериализовать объяснение.


## Выводы 

Вот буквально сегодня на работе столкнулся с подобной проблемой. Нужно было вывести некоторые метрики приложения из БД в графану. Но разработчик, который писал приложение, реализовал модель в БД таким образом, что просто так получить простую и понятную, элементарную информацию нет никакой возможности. Вместо простого подключению БД в качестве источника в Grafana и написания одного запроса нужно писать скрипт, который в цикле обращается к несокольким эндпоинтам API, выполняет преобразование полученных данных, записывает итоговые данные в отдельную БД с метриками. И уже из сторонней БД можно будет получить эти метрики. А можно было предусмотреть "информационную избыточность" и реализовать удобную модель данных для этих целей. Так сказать сделать эти метрики частью приложения. Тем более это можно сказать простые понятные пользователиские метрики, которые нужны буквально для любого сервиса. Плюс не зависеть от стороннего скрипта.

### Что для себя понял по итогам занятия? 
1) Информационная избыточность — это не зло, а инструмент.  
Разработчикам часто внушают: "Не дублируй данные, это антипаттерн!"
Но на практике дублирование может упростить жизнь.

Вывод: Иногда лучше дублировать данные, если это упрощает API, повышает читаемость или производительность.

2) Простая модель ≠ удобная модель  
Модель данных без избыточности может быть "чистой", но сложной в использовании:
- каждый запрос превращается в набор join'ов,
- API становится запутанным,
- каждый программист вынужден разбираться в деталях структуры.

Вывод: Хорошая модель — это не только нормализованная, но и удобная для пользователей (других разработчиков).

3) Можно заменить избыточность кэшем или View  
Если боишься дублирования стуктур данных, можно сделать кэшируемую функцию, которая "выглядит как данные", но пересчитывается на лету (и сбрасывается при обновлении). Это философия View из SQL.

Вывод: Ты можешь получить преимущества избыточности, даже не дублируя данные напрямую — через мемоизацию и вычисляемые представления.

4) Решать по use case'ам  
Не существует "правильной" модели данных в вакууме. Есть только модели, удобные или неудобные для конкретных задач:
- нужно быстро узнать "кто занят в 14:00" — храни `Dict[(time, room)] = talk`,
- нужно быстро найти "время и место переговоров по `ID`" — храни `Dict[talk] = (time, room)`,
- нужно и то, и другое — храни оба, но контролируй консистентность.

Вывод: Смотреть, какие запросы будут самыми частыми — и под них строить модель.

**Информационная избыточность — инструмент проектирования, а не антипаттерн.**